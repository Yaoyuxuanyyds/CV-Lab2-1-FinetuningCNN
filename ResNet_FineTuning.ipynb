{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据预处理与保存测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 定义数据预处理\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# ])\n",
    "\n",
    "# # 加载数据\n",
    "# dataset = datasets.ImageFolder(root='../CUB_200_2011/images')\n",
    "\n",
    "# # 取其中20%的数据作为测试集保存，并保存测试集不再改动\n",
    "# test_part = 0.2\n",
    "\n",
    "# total_count = len(dataset)\n",
    "# train_count = int((1-test_part) * total_count)\n",
    "# test_count = total_count - train_count\n",
    "\n",
    "# # 随机分割并定义处理方式\n",
    "# train_dataset, test_dataset = random_split(dataset, [train_count, test_count])\n",
    "# train_dataset.dataset.transform = transform\n",
    "# test_dataset.dataset.transform = transform\n",
    "\n",
    "# # 保存数据集和索引\n",
    "# def save_datasets(dataset, train_dataset, test_dataset):\n",
    "#     torch.save(dataset, 'dataset/full_dataset.pth')\n",
    "#     indices = (train_dataset.indices, test_dataset.indices)\n",
    "#     torch.save(indices, 'dataset/dataset_indices.pth')\n",
    "\n",
    "# save_datasets(dataset, train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载分割的数据集和索引文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集和索引\n",
    "def load_datasets():\n",
    "    full_dataset = torch.load('dataset/full_dataset.pth')\n",
    "    train_indices, test_indices = torch.load('dataset/dataset_indices.pth')        \n",
    "    train_dataset = Subset(full_dataset, train_indices)\n",
    "    test_dataset = Subset(full_dataset, test_indices)\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载预训练 Resnet 并选择冻结部分层，替换线性层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyResNet(nn.Module):\n",
    "    def __init__(self, chosen_model, num_classes=200):\n",
    "        super(MyResNet, self).__init__()\n",
    "        # 加载预训练的ResNet模型\n",
    "        if chosen_model == \"resnet18\":\n",
    "            self.resnet = models.resnet18(weights=True)\n",
    "        elif chosen_model == \"resnet34\":\n",
    "            self.resnet = models.resnet34(weights=True)\n",
    "        elif chosen_model == \"resnet50\":\n",
    "            self.resnet = models.resnet50(weights=True)\n",
    "        elif chosen_model == \"resnet101\":\n",
    "            self.resnet = models.resnet101(weights=True)    \n",
    "        elif chosen_model == \"resnet152\":\n",
    "            self.resnet = models.resnet152(weights=True)   \n",
    "        \n",
    "        # # 冻结部分层的参数\n",
    "        for param in self.resnet.layer1.parameters():\n",
    "            param.requires_grad = False\n",
    "        # for param in self.resnet.layer2.parameters():\n",
    "        #     param.requires_grad = False\n",
    "        # for param in self.resnet.layer3.parameters():\n",
    "        #     param.requires_grad = False\n",
    "        # for param in self.resnet.layer4.parameters():\n",
    "        #     param.requires_grad = False\n",
    "        # for param in self.resnet.layer5.parameters():\n",
    "        #     param.requires_grad = False\n",
    "\n",
    "\n",
    "        # 替换原来的fc层\n",
    "        num_ftrs = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, num_classes)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义训练 Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练函数\n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10, log_freq=5, saved_name='', device=torch.device('cpu')):\n",
    "    writer = SummaryWriter(log_dir = 'model_logs/'+saved_name)\n",
    "    batches_per_epoch = len(train_loader)\n",
    "    log_steps = int(batches_per_epoch / log_freq)  # 每隔log_steps个batch记录一次损失和准确率\n",
    "\n",
    "    # 训练过程\n",
    "    for epoch in range(num_epochs):\n",
    "        # 训练模式\n",
    "        model.train()  \n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        # 遍历数据集\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)  \n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # 优化\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # 每隔log_steps个batch记录一次损失和准确率\n",
    "            if (i + 1) % log_steps == 0 or i == batches_per_epoch - 1:\n",
    "                current_loss = running_loss / total\n",
    "                current_accuracy = correct / total\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Loss: {:.4f}, Training Accuracy: {:.4f}'.format(epoch+1, num_epochs, i+1, batches_per_epoch, current_loss, current_accuracy))\n",
    "                # 记录训练损失和准确率\n",
    "                writer.add_scalars('Loss', {'Training': current_loss}, epoch * batches_per_epoch + i)\n",
    "                writer.add_scalars('Accuracy', {'Training': current_accuracy}, epoch * batches_per_epoch + i)\n",
    "\n",
    "                running_loss = 0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "\n",
    "                # 验证模式\n",
    "                model.eval()\n",
    "                val_running_loss = 0.0\n",
    "                val_correct = 0\n",
    "                val_total = 0\n",
    "                with torch.no_grad():\n",
    "                    for val_images, val_labels in val_loader:\n",
    "                        # 将数据转移到GPU\n",
    "                        val_images, val_labels = val_images.to(device), val_labels.to(device)  \n",
    "\n",
    "                        val_outputs = model(val_images)\n",
    "                        val_loss = criterion(val_outputs, val_labels)\n",
    "                        val_running_loss += val_loss.item() * val_images.size(0)\n",
    "                        _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "                        val_total += val_labels.size(0)\n",
    "                        val_correct += (val_predicted == val_labels).sum().item()\n",
    "\n",
    "                val_loss = val_running_loss / val_total\n",
    "                val_accuracy = val_correct / val_total\n",
    "                print(f'Validation at Epoch {epoch+1}, Step {i+1}/{batches_per_epoch}, Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}')\n",
    "                # 记录验证损失和准确率\n",
    "                writer.add_scalars('Loss', {'Validation': val_loss}, epoch * batches_per_epoch + i)\n",
    "                writer.add_scalars('Accuracy', {'Validation': val_accuracy}, epoch * batches_per_epoch + i)\n",
    "\n",
    "                model.train()\n",
    "\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 执行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Training resnet50_0.001-5e-05_wd-1e-05_freezed-2_bt32......\n",
      "==================================================\n",
      "Using device: cuda\n",
      "Epoch [1/8], Step [26/266], Training Loss: 5.3139, Training Accuracy: 0.0132\n",
      "Validation at Epoch 1, Step 26/266, Validation Loss: 5.2226, Accuracy: 0.0180\n",
      "Epoch [1/8], Step [52/266], Training Loss: 5.1304, Training Accuracy: 0.0349\n",
      "Validation at Epoch 1, Step 52/266, Validation Loss: 4.9712, Accuracy: 0.0796\n",
      "Epoch [1/8], Step [78/266], Training Loss: 4.8744, Training Accuracy: 0.1358\n",
      "Validation at Epoch 1, Step 78/266, Validation Loss: 4.6605, Accuracy: 0.1624\n",
      "Epoch [1/8], Step [104/266], Training Loss: 4.6324, Training Accuracy: 0.1490\n",
      "Validation at Epoch 1, Step 104/266, Validation Loss: 4.4201, Accuracy: 0.1975\n",
      "Epoch [1/8], Step [130/266], Training Loss: 4.3520, Training Accuracy: 0.2007\n",
      "Validation at Epoch 1, Step 130/266, Validation Loss: 4.0594, Accuracy: 0.2410\n",
      "Epoch [1/8], Step [156/266], Training Loss: 4.0822, Training Accuracy: 0.2548\n",
      "Validation at Epoch 1, Step 156/266, Validation Loss: 3.8529, Accuracy: 0.2675\n",
      "Epoch [1/8], Step [182/266], Training Loss: 3.8159, Training Accuracy: 0.2812\n",
      "Validation at Epoch 1, Step 182/266, Validation Loss: 3.5357, Accuracy: 0.2665\n",
      "Epoch [1/8], Step [208/266], Training Loss: 3.6388, Training Accuracy: 0.3053\n",
      "Validation at Epoch 1, Step 208/266, Validation Loss: 3.3780, Accuracy: 0.3132\n",
      "Epoch [1/8], Step [234/266], Training Loss: 3.3810, Training Accuracy: 0.3401\n",
      "Validation at Epoch 1, Step 234/266, Validation Loss: 3.1752, Accuracy: 0.3737\n",
      "Epoch [1/8], Step [260/266], Training Loss: 3.1751, Training Accuracy: 0.3942\n",
      "Validation at Epoch 1, Step 260/266, Validation Loss: 2.9815, Accuracy: 0.3790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/8], Step [266/266], Training Loss: 3.1010, Training Accuracy: 0.4524\n",
      "Validation at Epoch 1, Step 266/266, Validation Loss: 2.8757, Accuracy: 0.3790\n",
      "Epoch [2/8], Step [26/266], Training Loss: 2.6855, Training Accuracy: 0.5228\n",
      "Validation at Epoch 2, Step 26/266, Validation Loss: 2.8544, Accuracy: 0.4310\n",
      "Epoch [2/8], Step [52/266], Training Loss: 2.6054, Training Accuracy: 0.5072\n",
      "Validation at Epoch 2, Step 52/266, Validation Loss: 2.6314, Accuracy: 0.4682\n",
      "Epoch [2/8], Step [78/266], Training Loss: 2.4493, Training Accuracy: 0.5481\n",
      "Validation at Epoch 2, Step 78/266, Validation Loss: 2.4810, Accuracy: 0.4713\n",
      "Epoch [2/8], Step [104/266], Training Loss: 2.4034, Training Accuracy: 0.5264\n",
      "Validation at Epoch 2, Step 104/266, Validation Loss: 2.3302, Accuracy: 0.4936\n",
      "Epoch [2/8], Step [130/266], Training Loss: 2.2088, Training Accuracy: 0.5841\n",
      "Validation at Epoch 2, Step 130/266, Validation Loss: 2.2167, Accuracy: 0.5318\n",
      "Epoch [2/8], Step [156/266], Training Loss: 2.0599, Training Accuracy: 0.6022\n",
      "Validation at Epoch 2, Step 156/266, Validation Loss: 2.1682, Accuracy: 0.4989\n",
      "Epoch [2/8], Step [182/266], Training Loss: 2.0937, Training Accuracy: 0.5829\n",
      "Validation at Epoch 2, Step 182/266, Validation Loss: 2.0062, Accuracy: 0.5594\n",
      "Epoch [2/8], Step [208/266], Training Loss: 1.8449, Training Accuracy: 0.6514\n",
      "Validation at Epoch 2, Step 208/266, Validation Loss: 1.9548, Accuracy: 0.5563\n",
      "Epoch [2/8], Step [234/266], Training Loss: 1.8503, Training Accuracy: 0.6358\n",
      "Validation at Epoch 2, Step 234/266, Validation Loss: 1.8658, Accuracy: 0.5828\n",
      "Epoch [2/8], Step [260/266], Training Loss: 1.8598, Training Accuracy: 0.6286\n",
      "Validation at Epoch 2, Step 260/266, Validation Loss: 1.7283, Accuracy: 0.6146\n",
      "Epoch [2/8], Step [266/266], Training Loss: 1.8504, Training Accuracy: 0.6131\n",
      "Validation at Epoch 2, Step 266/266, Validation Loss: 1.7255, Accuracy: 0.6051\n",
      "Epoch [3/8], Step [26/266], Training Loss: 1.3437, Training Accuracy: 0.8017\n",
      "Validation at Epoch 3, Step 26/266, Validation Loss: 1.7227, Accuracy: 0.6306\n",
      "Epoch [3/8], Step [52/266], Training Loss: 1.2704, Training Accuracy: 0.7897\n",
      "Validation at Epoch 3, Step 52/266, Validation Loss: 1.5979, Accuracy: 0.6401\n",
      "Epoch [3/8], Step [78/266], Training Loss: 1.2447, Training Accuracy: 0.7885\n",
      "Validation at Epoch 3, Step 78/266, Validation Loss: 1.5261, Accuracy: 0.6603\n",
      "Epoch [3/8], Step [104/266], Training Loss: 1.1933, Training Accuracy: 0.7897\n",
      "Validation at Epoch 3, Step 104/266, Validation Loss: 1.5350, Accuracy: 0.6454\n",
      "Epoch [3/8], Step [130/266], Training Loss: 1.1431, Training Accuracy: 0.8077\n",
      "Validation at Epoch 3, Step 130/266, Validation Loss: 1.4826, Accuracy: 0.6507\n",
      "Epoch [3/8], Step [156/266], Training Loss: 1.0952, Training Accuracy: 0.8089\n",
      "Validation at Epoch 3, Step 156/266, Validation Loss: 1.4707, Accuracy: 0.6348\n",
      "Epoch [3/8], Step [182/266], Training Loss: 1.0299, Training Accuracy: 0.8161\n",
      "Validation at Epoch 3, Step 182/266, Validation Loss: 1.4251, Accuracy: 0.6486\n",
      "Epoch [3/8], Step [208/266], Training Loss: 1.0156, Training Accuracy: 0.8161\n",
      "Validation at Epoch 3, Step 208/266, Validation Loss: 1.3464, Accuracy: 0.6826\n",
      "Epoch [3/8], Step [234/266], Training Loss: 1.0191, Training Accuracy: 0.8161\n",
      "Validation at Epoch 3, Step 234/266, Validation Loss: 1.3405, Accuracy: 0.6762\n",
      "Epoch [3/8], Step [260/266], Training Loss: 0.9467, Training Accuracy: 0.8089\n",
      "Validation at Epoch 3, Step 260/266, Validation Loss: 1.3382, Accuracy: 0.6890\n",
      "Epoch [3/8], Step [266/266], Training Loss: 0.9878, Training Accuracy: 0.7917\n",
      "Validation at Epoch 3, Step 266/266, Validation Loss: 1.3399, Accuracy: 0.6858\n",
      "Epoch [4/8], Step [26/266], Training Loss: 0.7073, Training Accuracy: 0.8954\n",
      "Validation at Epoch 4, Step 26/266, Validation Loss: 1.2582, Accuracy: 0.6932\n",
      "Epoch [4/8], Step [52/266], Training Loss: 0.6205, Training Accuracy: 0.9207\n",
      "Validation at Epoch 4, Step 52/266, Validation Loss: 1.2356, Accuracy: 0.7049\n",
      "Epoch [4/8], Step [78/266], Training Loss: 0.5989, Training Accuracy: 0.9171\n",
      "Validation at Epoch 4, Step 78/266, Validation Loss: 1.1990, Accuracy: 0.7102\n",
      "Epoch [4/8], Step [104/266], Training Loss: 0.5808, Training Accuracy: 0.9099\n",
      "Validation at Epoch 4, Step 104/266, Validation Loss: 1.2189, Accuracy: 0.6964\n",
      "Epoch [4/8], Step [130/266], Training Loss: 0.5844, Training Accuracy: 0.9062\n",
      "Validation at Epoch 4, Step 130/266, Validation Loss: 1.1560, Accuracy: 0.7219\n",
      "Epoch [4/8], Step [156/266], Training Loss: 0.5309, Training Accuracy: 0.9195\n",
      "Validation at Epoch 4, Step 156/266, Validation Loss: 1.1480, Accuracy: 0.7134\n",
      "Epoch [4/8], Step [182/266], Training Loss: 0.5049, Training Accuracy: 0.9375\n",
      "Validation at Epoch 4, Step 182/266, Validation Loss: 1.1688, Accuracy: 0.7049\n",
      "Epoch [4/8], Step [208/266], Training Loss: 0.5198, Training Accuracy: 0.9135\n",
      "Validation at Epoch 4, Step 208/266, Validation Loss: 1.1713, Accuracy: 0.6890\n",
      "Epoch [4/8], Step [234/266], Training Loss: 0.4815, Training Accuracy: 0.9171\n",
      "Validation at Epoch 4, Step 234/266, Validation Loss: 1.1178, Accuracy: 0.7240\n",
      "Epoch [4/8], Step [260/266], Training Loss: 0.4613, Training Accuracy: 0.9255\n",
      "Validation at Epoch 4, Step 260/266, Validation Loss: 1.0843, Accuracy: 0.7282\n",
      "Epoch [4/8], Step [266/266], Training Loss: 0.4347, Training Accuracy: 0.9524\n",
      "Validation at Epoch 4, Step 266/266, Validation Loss: 1.1041, Accuracy: 0.7208\n",
      "Epoch [5/8], Step [26/266], Training Loss: 0.3279, Training Accuracy: 0.9663\n",
      "Validation at Epoch 5, Step 26/266, Validation Loss: 1.1186, Accuracy: 0.7314\n",
      "Epoch [5/8], Step [52/266], Training Loss: 0.2822, Training Accuracy: 0.9736\n",
      "Validation at Epoch 5, Step 52/266, Validation Loss: 1.0657, Accuracy: 0.7473\n",
      "Epoch [5/8], Step [78/266], Training Loss: 0.2799, Training Accuracy: 0.9736\n",
      "Validation at Epoch 5, Step 78/266, Validation Loss: 1.0969, Accuracy: 0.7176\n",
      "Epoch [5/8], Step [104/266], Training Loss: 0.2918, Training Accuracy: 0.9567\n",
      "Validation at Epoch 5, Step 104/266, Validation Loss: 1.0753, Accuracy: 0.7272\n",
      "Epoch [5/8], Step [130/266], Training Loss: 0.2642, Training Accuracy: 0.9820\n",
      "Validation at Epoch 5, Step 130/266, Validation Loss: 1.0707, Accuracy: 0.7208\n",
      "Epoch [5/8], Step [156/266], Training Loss: 0.2699, Training Accuracy: 0.9675\n",
      "Validation at Epoch 5, Step 156/266, Validation Loss: 1.0250, Accuracy: 0.7442\n",
      "Epoch [5/8], Step [182/266], Training Loss: 0.2692, Training Accuracy: 0.9627\n",
      "Validation at Epoch 5, Step 182/266, Validation Loss: 1.0435, Accuracy: 0.7314\n",
      "Epoch [5/8], Step [208/266], Training Loss: 0.2814, Training Accuracy: 0.9531\n",
      "Validation at Epoch 5, Step 208/266, Validation Loss: 1.0593, Accuracy: 0.7208\n",
      "Epoch [5/8], Step [234/266], Training Loss: 0.2476, Training Accuracy: 0.9712\n",
      "Validation at Epoch 5, Step 234/266, Validation Loss: 1.0614, Accuracy: 0.7197\n",
      "Epoch [5/8], Step [260/266], Training Loss: 0.2408, Training Accuracy: 0.9700\n",
      "Validation at Epoch 5, Step 260/266, Validation Loss: 1.0775, Accuracy: 0.7102\n",
      "Epoch [5/8], Step [266/266], Training Loss: 0.2064, Training Accuracy: 0.9821\n",
      "Validation at Epoch 5, Step 266/266, Validation Loss: 1.0561, Accuracy: 0.7219\n",
      "Epoch [6/8], Step [26/266], Training Loss: 0.1724, Training Accuracy: 0.9868\n",
      "Validation at Epoch 6, Step 26/266, Validation Loss: 1.0607, Accuracy: 0.7314\n",
      "Epoch [6/8], Step [52/266], Training Loss: 0.1619, Training Accuracy: 0.9832\n",
      "Validation at Epoch 6, Step 52/266, Validation Loss: 1.0226, Accuracy: 0.7335\n",
      "Epoch [6/8], Step [78/266], Training Loss: 0.1437, Training Accuracy: 0.9880\n",
      "Validation at Epoch 6, Step 78/266, Validation Loss: 1.0344, Accuracy: 0.7463\n",
      "Epoch [6/8], Step [104/266], Training Loss: 0.1217, Training Accuracy: 0.9952\n",
      "Validation at Epoch 6, Step 104/266, Validation Loss: 1.0269, Accuracy: 0.7420\n",
      "Epoch [6/8], Step [130/266], Training Loss: 0.1337, Training Accuracy: 0.9940\n",
      "Validation at Epoch 6, Step 130/266, Validation Loss: 1.0328, Accuracy: 0.7304\n",
      "Epoch [6/8], Step [156/266], Training Loss: 0.1242, Training Accuracy: 0.9904\n",
      "Validation at Epoch 6, Step 156/266, Validation Loss: 1.0100, Accuracy: 0.7420\n",
      "Epoch [6/8], Step [182/266], Training Loss: 0.1131, Training Accuracy: 0.9940\n",
      "Validation at Epoch 6, Step 182/266, Validation Loss: 1.0343, Accuracy: 0.7335\n",
      "Epoch [6/8], Step [208/266], Training Loss: 0.1161, Training Accuracy: 0.9916\n",
      "Validation at Epoch 6, Step 208/266, Validation Loss: 1.0530, Accuracy: 0.7282\n",
      "Epoch [6/8], Step [234/266], Training Loss: 0.1199, Training Accuracy: 0.9892\n",
      "Validation at Epoch 6, Step 234/266, Validation Loss: 1.0856, Accuracy: 0.7166\n",
      "Epoch [6/8], Step [260/266], Training Loss: 0.1232, Training Accuracy: 0.9880\n",
      "Validation at Epoch 6, Step 260/266, Validation Loss: 1.0416, Accuracy: 0.7240\n",
      "Epoch [6/8], Step [266/266], Training Loss: 0.1116, Training Accuracy: 1.0000\n",
      "Validation at Epoch 6, Step 266/266, Validation Loss: 1.0288, Accuracy: 0.7197\n",
      "Epoch [7/8], Step [26/266], Training Loss: 0.0829, Training Accuracy: 1.0000\n",
      "Validation at Epoch 7, Step 26/266, Validation Loss: 1.0511, Accuracy: 0.7272\n",
      "Epoch [7/8], Step [52/266], Training Loss: 0.0750, Training Accuracy: 0.9988\n",
      "Validation at Epoch 7, Step 52/266, Validation Loss: 1.0476, Accuracy: 0.7282\n",
      "Epoch [7/8], Step [78/266], Training Loss: 0.0679, Training Accuracy: 0.9988\n",
      "Validation at Epoch 7, Step 78/266, Validation Loss: 1.0162, Accuracy: 0.7420\n",
      "Epoch [7/8], Step [104/266], Training Loss: 0.0708, Training Accuracy: 0.9976\n",
      "Validation at Epoch 7, Step 104/266, Validation Loss: 1.0246, Accuracy: 0.7420\n",
      "Epoch [7/8], Step [130/266], Training Loss: 0.0606, Training Accuracy: 1.0000\n",
      "Validation at Epoch 7, Step 130/266, Validation Loss: 1.0019, Accuracy: 0.7410\n",
      "Epoch [7/8], Step [156/266], Training Loss: 0.0645, Training Accuracy: 0.9988\n",
      "Validation at Epoch 7, Step 156/266, Validation Loss: 1.0282, Accuracy: 0.7304\n",
      "Epoch [7/8], Step [182/266], Training Loss: 0.0594, Training Accuracy: 0.9976\n",
      "Validation at Epoch 7, Step 182/266, Validation Loss: 1.0228, Accuracy: 0.7389\n",
      "Epoch [7/8], Step [208/266], Training Loss: 0.0603, Training Accuracy: 0.9976\n",
      "Validation at Epoch 7, Step 208/266, Validation Loss: 1.0217, Accuracy: 0.7367\n",
      "Epoch [7/8], Step [234/266], Training Loss: 0.0713, Training Accuracy: 0.9928\n",
      "Validation at Epoch 7, Step 234/266, Validation Loss: 1.0510, Accuracy: 0.7282\n",
      "Epoch [7/8], Step [260/266], Training Loss: 0.0672, Training Accuracy: 0.9988\n",
      "Validation at Epoch 7, Step 260/266, Validation Loss: 1.0180, Accuracy: 0.7314\n",
      "Epoch [7/8], Step [266/266], Training Loss: 0.0799, Training Accuracy: 1.0000\n",
      "Validation at Epoch 7, Step 266/266, Validation Loss: 1.0082, Accuracy: 0.7346\n",
      "Epoch [8/8], Step [26/266], Training Loss: 0.0520, Training Accuracy: 0.9964\n",
      "Validation at Epoch 8, Step 26/266, Validation Loss: 1.0633, Accuracy: 0.7166\n",
      "Epoch [8/8], Step [52/266], Training Loss: 0.0474, Training Accuracy: 0.9976\n",
      "Validation at Epoch 8, Step 52/266, Validation Loss: 1.0042, Accuracy: 0.7473\n",
      "Epoch [8/8], Step [78/266], Training Loss: 0.0386, Training Accuracy: 1.0000\n",
      "Validation at Epoch 8, Step 78/266, Validation Loss: 1.0103, Accuracy: 0.7346\n",
      "Epoch [8/8], Step [104/266], Training Loss: 0.0394, Training Accuracy: 1.0000\n",
      "Validation at Epoch 8, Step 104/266, Validation Loss: 1.0360, Accuracy: 0.7325\n",
      "Epoch [8/8], Step [130/266], Training Loss: 0.0390, Training Accuracy: 1.0000\n",
      "Validation at Epoch 8, Step 130/266, Validation Loss: 1.0431, Accuracy: 0.7314\n",
      "Epoch [8/8], Step [156/266], Training Loss: 0.0421, Training Accuracy: 1.0000\n",
      "Validation at Epoch 8, Step 156/266, Validation Loss: 1.0351, Accuracy: 0.7357\n",
      "Epoch [8/8], Step [182/266], Training Loss: 0.0399, Training Accuracy: 1.0000\n",
      "Validation at Epoch 8, Step 182/266, Validation Loss: 1.0115, Accuracy: 0.7367\n",
      "Epoch [8/8], Step [208/266], Training Loss: 0.0395, Training Accuracy: 0.9988\n",
      "Validation at Epoch 8, Step 208/266, Validation Loss: 1.0267, Accuracy: 0.7357\n",
      "Epoch [8/8], Step [234/266], Training Loss: 0.0445, Training Accuracy: 0.9964\n",
      "Validation at Epoch 8, Step 234/266, Validation Loss: 1.0298, Accuracy: 0.7261\n",
      "Epoch [8/8], Step [260/266], Training Loss: 0.0369, Training Accuracy: 0.9988\n",
      "Validation at Epoch 8, Step 260/266, Validation Loss: 1.0066, Accuracy: 0.7378\n",
      "Epoch [8/8], Step [266/266], Training Loss: 0.0524, Training Accuracy: 1.0000\n",
      "Validation at Epoch 8, Step 266/266, Validation Loss: 1.0094, Accuracy: 0.7431\n"
     ]
    }
   ],
   "source": [
    "# 设置\n",
    "chosen_model = 'resnet50'\n",
    "batch_size = 32\n",
    "num_epoches = 8\n",
    "log_freq = 10\n",
    "train_val_split = 0.9\n",
    "# 网格查找超参数\n",
    "lr_new_list = [0.001]\n",
    "lr_old_list = [0.00005]\n",
    "regularization_list = [1e-5]\n",
    "\n",
    "# 加载数据集\n",
    "train_dataset, test_dataset = load_datasets()\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_val_split, 1-train_val_split])\n",
    "# 创建DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# 每个组合依次训练\n",
    "for lr_new in lr_new_list:\n",
    "    for lr_old in lr_old_list:\n",
    "        for regularization in regularization_list:\n",
    "            saved_name =chosen_model+f'_{lr_new}-{lr_old}_wd-{regularization}_freezed-2_bt32'\n",
    "            print('='*50)\n",
    "            print('Training '+saved_name+'......')\n",
    "            print('='*50)\n",
    "            \n",
    "            # 检查GPU是否可用\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            print(\"Using device:\", device)\n",
    "            # 清空GPU缓存\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            # 创建模型实例\n",
    "            model = MyResNet(chosen_model)\n",
    "            model.to(device)  \n",
    "\n",
    "            # 损失函数\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            # 优化器\n",
    "            fc_params = model.resnet.fc.parameters()\n",
    "            base_params = filter(lambda p: id(p) not in map(id, fc_params), model.resnet.parameters())\n",
    "            optimizer = optim.Adam([\n",
    "                {'params': base_params, 'lr': lr_old, 'weight_decay': regularization},  \n",
    "                {'params': fc_params, 'lr': lr_new, 'weight_decay': regularization}     \n",
    "            ])\n",
    "            # 训练\n",
    "            train_model(model, criterion, optimizer, train_loader, val_loader, num_epoches, log_freq, saved_name, device)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'weights/' + saved_name + '.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载模型权重并测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 76.84478371501272%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('weights/'+ saved_name +'.pth'))\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "\n",
    "        images, labels = images.to(device), labels.to(device)  # 将数据转移到GPU\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print('Test Accuracy: {}%'.format(accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
