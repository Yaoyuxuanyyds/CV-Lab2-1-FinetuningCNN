{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 定义数据预处理\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# ])\n",
    "\n",
    "# # 加载数据\n",
    "# dataset = datasets.ImageFolder(root='CUB_200_2011/images')\n",
    "\n",
    "# # 取其中20%的数据作为测试集保存，并保存测试集不再改动\n",
    "# total_count = len(dataset)\n",
    "# train_count = int(0.8 * total_count)\n",
    "# test_count = total_count - train_count\n",
    "\n",
    "# # 随机分割并定义处理方式\n",
    "# train_dataset, test_dataset = random_split(dataset, [train_count, test_count])\n",
    "# train_dataset.dataset.transform = transform\n",
    "# test_dataset.dataset.transform = transform\n",
    "\n",
    "# # 保存数据集和索引\n",
    "# def save_datasets(dataset, train_dataset, test_dataset):\n",
    "#     torch.save(dataset, 'dataset/full_dataset.pth')\n",
    "#     indices = (train_dataset.indices, test_dataset.indices)\n",
    "#     torch.save(indices, 'dataset/dataset_indices.pth')\n",
    "\n",
    "# save_datasets(dataset, train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集和索引\n",
    "def load_datasets():\n",
    "    full_dataset = torch.load('dataset/full_dataset.pth')\n",
    "    train_indices, test_indices = torch.load('dataset/dataset_indices.pth')        \n",
    "    train_dataset = Subset(full_dataset, train_indices)\n",
    "    test_dataset = Subset(full_dataset, test_indices)\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyResNet(nn.Module):\n",
    "    def __init__(self, chosen_model, num_classes=200):\n",
    "        super(MyResNet, self).__init__()\n",
    "        # 加载预训练的ResNet模型\n",
    "        if chosen_model == \"resnet18\":\n",
    "            self.resnet = models.resnet18(weights=True)\n",
    "        elif chosen_model == \"resnet34\":\n",
    "            self.resnet = models.resnet34(weights=True)\n",
    "        elif chosen_model == \"resnet50\":\n",
    "            self.resnet = models.resnet50(weights=True)\n",
    "        elif chosen_model == \"resnet101\":\n",
    "            self.resnet = models.resnet101(weights=True)    \n",
    "        elif chosen_model == \"resnet152\":\n",
    "            self.resnet = models.resnet152(weights=True)   \n",
    "        \n",
    "        # # 冻结部分层的参数\n",
    "        for param in self.resnet.layer1.parameters():\n",
    "            param.requires_grad = False\n",
    "        # for param in self.resnet.layer2.parameters():\n",
    "        #     param.requires_grad = False\n",
    "        # for param in self.resnet.layer3.parameters():\n",
    "        #     param.requires_grad = False\n",
    "        # for param in self.resnet.layer4.parameters():\n",
    "        #     param.requires_grad = False\n",
    "        # for param in self.resnet.layer5.parameters():\n",
    "        #     param.requires_grad = False\n",
    "\n",
    "\n",
    "        # 替换原来的fc层\n",
    "        num_ftrs = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, num_classes)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练函数\n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10, log_freq=5, saved_name='', device=torch.device('cpu')):\n",
    "    writer = SummaryWriter(log_dir = 'model_logs/'+saved_name)\n",
    "    batches_per_epoch = len(train_loader)\n",
    "    log_steps = int(batches_per_epoch / log_freq)  # 每隔log_steps个batch记录一次损失和准确率\n",
    "\n",
    "    # 训练过程\n",
    "    for epoch in range(num_epochs):\n",
    "        # 训练模式\n",
    "        model.train()  \n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        # 遍历数据集\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)  \n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # 优化\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # 每隔log_steps个batch记录一次损失和准确率\n",
    "            if (i + 1) % log_steps == 0 or i == batches_per_epoch - 1:\n",
    "                current_loss = running_loss / total\n",
    "                current_accuracy = correct / total\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Loss: {:.4f}, Training Accuracy: {:.4f}'.format(epoch+1, num_epochs, i+1, batches_per_epoch, current_loss, current_accuracy))\n",
    "                # 记录训练损失和准确率\n",
    "                writer.add_scalars('Loss', {'Training': current_loss}, epoch * batches_per_epoch + i)\n",
    "                writer.add_scalars('Accuracy', {'Training': current_accuracy}, epoch * batches_per_epoch + i)\n",
    "\n",
    "                running_loss = 0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "\n",
    "                # 验证模式\n",
    "                model.eval()\n",
    "                val_running_loss = 0.0\n",
    "                val_correct = 0\n",
    "                val_total = 0\n",
    "                with torch.no_grad():\n",
    "                    for val_images, val_labels in val_loader:\n",
    "                        # 将数据转移到GPU\n",
    "                        val_images, val_labels = val_images.to(device), val_labels.to(device)  \n",
    "\n",
    "                        val_outputs = model(val_images)\n",
    "                        val_loss = criterion(val_outputs, val_labels)\n",
    "                        val_running_loss += val_loss.item() * val_images.size(0)\n",
    "                        _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "                        val_total += val_labels.size(0)\n",
    "                        val_correct += (val_predicted == val_labels).sum().item()\n",
    "\n",
    "                val_loss = val_running_loss / val_total\n",
    "                val_accuracy = val_correct / val_total\n",
    "                print(f'Validation at Epoch {epoch+1}, Step {i+1}/{batches_per_epoch}, Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}')\n",
    "                # 记录验证损失和准确率\n",
    "                writer.add_scalars('Loss', {'Validation': val_loss}, epoch * batches_per_epoch + i)\n",
    "                writer.add_scalars('Accuracy', {'Validation': val_accuracy}, epoch * batches_per_epoch + i)\n",
    "\n",
    "                model.train()\n",
    "\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置\n",
    "chosen_model = 'resnet50'\n",
    "batch_size = 32\n",
    "num_epoches = 10\n",
    "log_freq = 10\n",
    "train_val_split = 0.9\n",
    "\n",
    "\n",
    "# 加载数据集\n",
    "train_dataset, test_dataset = load_datasets()\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_val_split, 1-train_val_split])\n",
    "# 创建DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False)\n",
    "\n",
    "# 网格查找超参数\n",
    "lr_new_list = [0.001]\n",
    "lr_old_list = [0.00005]\n",
    "regularization_list = [1e-5]\n",
    "\n",
    "# 每个组合依次训练\n",
    "for lr_new in lr_new_list:\n",
    "    for lr_old in lr_old_list:\n",
    "        for regularization in regularization_list:\n",
    "            saved_name =chosen_model+f'_{lr_new}-{lr_old}_wd-{regularization}_freezed-1'\n",
    "            print('='*50)\n",
    "            print('Training '+saved_name+'......')\n",
    "            print('='*50)\n",
    "            \n",
    "            # 检查GPU是否可用\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            print(\"Using device:\", device)\n",
    "            # 清空GPU缓存\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            # 创建模型实例\n",
    "            model = MyResNet(chosen_model)\n",
    "            model.to(device)  \n",
    "\n",
    "            # 损失函数\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            # 优化器\n",
    "            fc_params = model.resnet.fc.parameters()\n",
    "            base_params = filter(lambda p: id(p) not in map(id, fc_params), model.resnet.parameters())\n",
    "            optimizer = optim.Adam([\n",
    "                {'params': base_params, 'lr': lr_old, 'weight_decay': regularization},  \n",
    "                {'params': fc_params, 'lr': lr_new, 'weight_decay': regularization}     \n",
    "            ])\n",
    "            # 训练\n",
    "            train_model(model, criterion, optimizer, train_loader, val_loader, num_epoches, log_freq, saved_name, device)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'weights/' + saved_name + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('weights/'+ saved_name +'.pth'))\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "\n",
    "        images, labels = images.to(device), labels.to(device)  # 将数据转移到GPU\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print('Test Accuracy: {}%'.format(accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
